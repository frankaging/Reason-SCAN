{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reason for these tests\n",
    "A PR is raised in [ISSUE_1](https://github.com/frankaging/Reason-SCAN/issues/1), the reporter finds some discrepancies in split numbers. Specifically, the `test` split in our main data frame, is not matching up with our sub-test splits as `p1`, `p2` and `p3`. This PR further exposes another issue with our documentations about the splits (i.e., how we generate our splits). Thus, we use this live debug notebook to address these comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset from file: ../../ReaSCAN-v1.0/ReaSCAN-compositional-p1-test/data-compositional-splits.txt...\n",
      "921\n",
      "Reading dataset from file: ../../ReaSCAN-v1.0/ReaSCAN-compositional-p2-test/data-compositional-splits.txt...\n",
      "2120\n",
      "Reading dataset from file: ../../ReaSCAN-v1.0/ReaSCAN-compositional-p3-test/data-compositional-splits.txt...\n",
      "2712\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "p1_test_path_to_data = \"../../ReaSCAN-v1.0/ReaSCAN-compositional-p1-test/data-compositional-splits.txt\"\n",
    "print(f\"Reading dataset from file: {p1_test_path_to_data}...\")\n",
    "p1_test_data = json.load(open(p1_test_path_to_data, \"r\"))\n",
    "print(len(p1_test_data[\"examples\"][\"test\"]))\n",
    "\n",
    "p2_test_path_to_data = \"../../ReaSCAN-v1.0/ReaSCAN-compositional-p2-test/data-compositional-splits.txt\"\n",
    "print(f\"Reading dataset from file: {p2_test_path_to_data}...\")\n",
    "p2_test_data = json.load(open(p2_test_path_to_data, \"r\"))\n",
    "print(len(p2_test_data[\"examples\"][\"test\"]))\n",
    "\n",
    "p3_test_path_to_data = \"../../ReaSCAN-v1.0/ReaSCAN-compositional-p3-test/data-compositional-splits.txt\"\n",
    "print(f\"Reading dataset from file: {p3_test_path_to_data}...\")\n",
    "p3_test_data = json.load(open(p3_test_path_to_data, \"r\"))\n",
    "print(len(p3_test_data[\"examples\"][\"test\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5753"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p1_test_data[\"examples\"][\"test\"]) + len(p2_test_data[\"examples\"][\"test\"]) + len(p3_test_data[\"examples\"][\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset from file: ../../ReaSCAN-v1.0/ReaSCAN-compositional/data-compositional-splits.txt...\n"
     ]
    }
   ],
   "source": [
    "ReaSCAN_path_to_data = \"../../ReaSCAN-v1.0/ReaSCAN-compositional/data-compositional-splits.txt\"\n",
    "print(f\"Reading dataset from file: {ReaSCAN_path_to_data}...\")\n",
    "ReaSCAN_data = json.load(open(ReaSCAN_path_to_data, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1 test example count=907\n",
      "p2 test example count=2122\n",
      "p3 test example count=2724\n"
     ]
    }
   ],
   "source": [
    "p1_test_example_filtered = []\n",
    "p2_test_example_filtered = []\n",
    "p3_test_example_filtered = []\n",
    "for example in ReaSCAN_data[\"examples\"][\"test\"]:\n",
    "    if example['derivation'] == \"$OBJ_0\":\n",
    "        p1_test_example_filtered += [example]\n",
    "    elif example['derivation'] == \"$OBJ_0 ^ $OBJ_1\":\n",
    "        p2_test_example_filtered += [example]\n",
    "    elif example['derivation'] == \"$OBJ_0 ^ $OBJ_1 & $OBJ_2\":\n",
    "        p3_test_example_filtered += [example]\n",
    "print(f\"p1 test example count={len(p1_test_example_filtered)}\")\n",
    "print(f\"p2 test example count={len(p2_test_example_filtered)}\")\n",
    "print(f\"p3 test example count={len(p3_test_example_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5753"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p1_test_example_filtered) + len(p2_test_example_filtered) + len(p3_test_example_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, as you can see `p1 test example count` should be equal to `921`, but it is not. However, you can see that the total number of test examples matches up. The **root cause** potentially is that our sub-test splits are created asynchronously with the test split in the main data. \n",
    "\n",
    "Before confirming the **root cause**, we need to first analyze what is the actual **impact** on performance numbers? Are they changing our results qualitatively? or just quantitatively? We come up with some tests around this issue starting from basic to more complex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test-1: Validity\n",
    "We need to ensure our sub-test splits **only** contain commands appear in the training set. Otherwise, our test splits become compositional splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_command_set = set([])\n",
    "for example in ReaSCAN_data[\"examples\"][\"train\"]:\n",
    "    train_command_set.add(example[\"command\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-1 Passed\n"
     ]
    }
   ],
   "source": [
    "for example in p1_test_data[\"examples\"][\"test\"]:\n",
    "    assert example[\"command\"] in train_command_set\n",
    "for example in p2_test_data[\"examples\"][\"test\"]:\n",
    "    assert example[\"command\"] in train_command_set\n",
    "for example in p3_test_data[\"examples\"][\"test\"]:\n",
    "    assert example[\"command\"] in train_command_set\n",
    "print(\"Test-1 Passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test-2: Overestimating?\n",
    "What about the shape world? Are there overlaps between train and test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "train_example_hash = set([])\n",
    "for example in ReaSCAN_data[\"examples\"][\"train\"]:\n",
    "    example_hash_object = hashlib.md5(json.dumps(example).encode('utf-8'))\n",
    "    train_example_hash.add(example_hash_object.hexdigest())\n",
    "assert len(train_example_hash) == len(ReaSCAN_data[\"examples\"][\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_test_example_hash = set([])\n",
    "for example in p1_test_data[\"examples\"][\"test\"]:\n",
    "    example_hash_object = hashlib.md5(json.dumps(example).encode('utf-8'))\n",
    "    p1_test_example_hash.add(example_hash_object.hexdigest())\n",
    "assert len(p1_test_example_hash) == len(p1_test_data[\"examples\"][\"test\"])\n",
    "\n",
    "p2_test_example_hash = set([])\n",
    "for example in p2_test_data[\"examples\"][\"test\"]:\n",
    "    example_hash_object = hashlib.md5(json.dumps(example).encode('utf-8'))\n",
    "    p2_test_example_hash.add(example_hash_object.hexdigest())\n",
    "assert len(p2_test_example_hash) == len(p2_test_data[\"examples\"][\"test\"])\n",
    "\n",
    "p3_test_example_hash = set([])\n",
    "for example in p3_test_data[\"examples\"][\"test\"]:\n",
    "    example_hash_object = hashlib.md5(json.dumps(example).encode('utf-8'))\n",
    "    p3_test_example_hash.add(example_hash_object.hexdigest())\n",
    "assert len(p3_test_example_hash) == len(p3_test_data[\"examples\"][\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_test_dup_count = 0\n",
    "for hash_str in p1_test_example_hash:\n",
    "    if hash_str in train_example_hash:\n",
    "        p1_test_dup_count += 1\n",
    "        \n",
    "p2_test_dup_count = 0\n",
    "for hash_str in p2_test_example_hash:\n",
    "    if hash_str in train_example_hash:\n",
    "        p2_test_dup_count += 1\n",
    "\n",
    "p3_test_dup_count = 0\n",
    "for hash_str in p3_test_example_hash:\n",
    "    if hash_str in train_example_hash:\n",
    "        p3_test_dup_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1_test_dup_count=858\n",
      "p2_test_dup_count=1982\n",
      "p3_test_dup_count=2548\n"
     ]
    }
   ],
   "source": [
    "print(f\"p1_test_dup_count={p1_test_dup_count}\")\n",
    "print(f\"p2_test_dup_count={p2_test_dup_count}\")\n",
    "print(f\"p3_test_dup_count={p3_test_dup_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_p1_test_example_hash = set([])\n",
    "for example in p1_test_example_filtered:\n",
    "    example_hash_object = hashlib.md5(json.dumps(example).encode('utf-8'))\n",
    "    main_p1_test_example_hash.add(example_hash_object.hexdigest())\n",
    "assert len(main_p1_test_example_hash) == len(p1_test_example_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_p1_test_dup_count = 0\n",
    "for hash_str in main_p1_test_example_hash:\n",
    "    if hash_str in train_example_hash:\n",
    "        main_p1_test_dup_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main_p1_test_dup_count=0\n"
     ]
    }
   ],
   "source": [
    "print(f\"main_p1_test_dup_count={main_p1_test_dup_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: Yes. As you can see, we have many duplicated examples in our random tests. This means that, we need to use updated testing splits for evaluating performance. As a result, the **table 3** in the paper needs to be updated since it is now overestimating model performance for non-generalizing test splits (e.g., `p1`, `p2` nad `p3`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Action Required**: Need to re-evaluation model performance on those splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test-3: Does this issue affect any other generalization splits?\n",
    "Does our generalization splits containing duplicates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_example_hash_set(split):\n",
    "    split_test_path_to_data = f\"../../ReaSCAN-v1.0/ReaSCAN-compositional-{split}/data-compositional-splits.txt\"\n",
    "    print(f\"Reading dataset from file: {split_test_path_to_data}...\")\n",
    "    split_test_data = json.load(open(split_test_path_to_data, \"r\"))\n",
    "    split_test_data_test_example_hash = set([])\n",
    "    for example in split_test_data[\"examples\"][\"test\"]:\n",
    "        example_hash_object = hashlib.md5(json.dumps(example).encode('utf-8'))\n",
    "        split_test_data_test_example_hash.add(example_hash_object.hexdigest())\n",
    "    assert len(split_test_data_test_example_hash) == len(split_test_data[\"examples\"][\"test\"])\n",
    "    return split_test_data_test_example_hash\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset from file: ../../ReaSCAN-v1.0/ReaSCAN-compositional-a1/data-compositional-splits.txt...\n",
      "Reading dataset from file: ../../ReaSCAN-v1.0/ReaSCAN-compositional-a2/data-compositional-splits.txt...\n",
      "Reading dataset from file: ../../ReaSCAN-v1.0/ReaSCAN-compositional-a3/data-compositional-splits.txt...\n",
      "Reading dataset from file: ../../ReaSCAN-v1.0/ReaSCAN-compositional-b1/data-compositional-splits.txt...\n",
      "Reading dataset from file: ../../ReaSCAN-v1.0/ReaSCAN-compositional-b2/data-compositional-splits.txt...\n",
      "Reading dataset from file: ../../ReaSCAN-v1.0/ReaSCAN-compositional-c1/data-compositional-splits.txt...\n",
      "Reading dataset from file: ../../ReaSCAN-v1.0/ReaSCAN-compositional-c2/data-compositional-splits.txt...\n"
     ]
    }
   ],
   "source": [
    "a1_hash = get_example_hash_set(\"a1\")\n",
    "a2_hash = get_example_hash_set(\"a2\")\n",
    "a3_hash = get_example_hash_set(\"a3\")\n",
    "\n",
    "b1_hash = get_example_hash_set(\"b1\")\n",
    "b2_hash = get_example_hash_set(\"b2\")\n",
    "\n",
    "c1_hash = get_example_hash_set(\"c1\")\n",
    "c2_hash = get_example_hash_set(\"c2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1_dup_count = 0\n",
    "for hash_str in a1_hash:\n",
    "    if hash_str in train_example_hash:\n",
    "        a1_dup_count += 1\n",
    "a2_dup_count = 0\n",
    "for hash_str in a2_hash:\n",
    "    if hash_str in train_example_hash:\n",
    "        a2_dup_count += 1\n",
    "a3_dup_count = 0\n",
    "for hash_str in a3_hash:\n",
    "    if hash_str in train_example_hash:\n",
    "        a3_dup_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1_dup_count=0\n",
      "a2_dup_count=0\n",
      "a3_dup_count=0\n"
     ]
    }
   ],
   "source": [
    "print(f\"a1_dup_count={a1_dup_count}\")\n",
    "print(f\"a2_dup_count={a2_dup_count}\")\n",
    "print(f\"a3_dup_count={a3_dup_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_dup_count = 0\n",
    "for hash_str in b1_hash:\n",
    "    if hash_str in train_example_hash:\n",
    "        b1_dup_count += 1\n",
    "b2_dup_count = 0\n",
    "for hash_str in b2_hash:\n",
    "    if hash_str in train_example_hash:\n",
    "        b2_dup_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b1_dup_count=0\n",
      "b2_dup_count=0\n"
     ]
    }
   ],
   "source": [
    "print(f\"b1_dup_count={b1_dup_count}\")\n",
    "print(f\"b2_dup_count={b2_dup_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_dup_count = 0\n",
    "for hash_str in c1_hash:\n",
    "    if hash_str in train_example_hash:\n",
    "        c1_dup_count += 1\n",
    "c2_dup_count = 0\n",
    "for hash_str in c2_hash:\n",
    "    if hash_str in train_example_hash:\n",
    "        c2_dup_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1_dup_count=0\n",
      "c2_dup_count=0\n"
     ]
    }
   ],
   "source": [
    "print(f\"c1_dup_count={c1_dup_count}\")\n",
    "print(f\"c2_dup_count={c2_dup_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: No."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test-4: What about correctness of generalization splits in general?\n",
    "We see there is no duplicate, but what about general correctness? Are their created correctly? In this section, we add more sanity checks to show correctness of each generalization split.\n",
    "\n",
    "For each split, we verify two things:\n",
    "* the generalization split can ONLY contain test examples that it is designed to test.\n",
    "* the training split DOES NOT contain examples that are aligned with the generalization split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A1:novel color modifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset from file: ../../ReaSCAN-v1.0/ReaSCAN-compositional-a1/data-compositional-splits.txt...\n"
     ]
    }
   ],
   "source": [
    "split_test_path_to_data = f\"../../ReaSCAN-v1.0/ReaSCAN-compositional-a1/data-compositional-splits.txt\"\n",
    "print(f\"Reading dataset from file: {split_test_path_to_data}...\")\n",
    "split_test_data = json.load(open(split_test_path_to_data, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in split_test_data[\"examples\"][\"test\"]:\n",
    "    assert \"yellow,square\" in example[\"command\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in ReaSCAN_data[\"examples\"][\"train\"]:\n",
    "    assert \"yellow,square\" not in example[\"command\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2: novel color attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset from file: ../../ReaSCAN-v1.0/ReaSCAN-compositional-a2/data-compositional-splits.txt...\n"
     ]
    }
   ],
   "source": [
    "# this test may be a little to weak for now. maybe improve it to verify the shape world?\n",
    "split_test_path_to_data = f\"../../ReaSCAN-v1.0/ReaSCAN-compositional-a2/data-compositional-splits.txt\"\n",
    "print(f\"Reading dataset from file: {split_test_path_to_data}...\")\n",
    "split_test_data = json.load(open(split_test_path_to_data, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in ReaSCAN_data[\"examples\"][\"train\"]:\n",
    "    assert \"red,square\" not in example[\"command\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in split_test_data[\"examples\"][\"test\"]:\n",
    "    if \"red,square\" not in example[\"command\"]:\n",
    "        # then, some background object referred in the command needs to be a red square!!\n",
    "        if example[\"derivation\"] == \"$OBJ_0\":\n",
    "            assert example['situation']['placed_objects']['0']['object']['shape'] == \"square\"\n",
    "            assert example['situation']['placed_objects']['0']['object']['color'] == \"red\"\n",
    "        elif example[\"derivation\"] == \"$OBJ_0 ^ $OBJ_1\":\n",
    "            assert example['situation']['placed_objects']['0']['object']['shape'] == \"square\" or example['situation']['placed_objects']['1']['object']['shape'] == \"square\"\n",
    "            assert example['situation']['placed_objects']['0']['object']['color'] == \"red\" or example['situation']['placed_objects']['1']['object']['color'] == \"red\"\n",
    "        elif example[\"derivation\"] == \"$OBJ_0 ^ $OBJ_1 & $OBJ_2\":\n",
    "            assert example['situation']['placed_objects']['0']['object']['shape'] == \"square\" or example['situation']['placed_objects']['1']['object']['shape'] == \"square\" or example['situation']['placed_objects']['2']['object']['shape'] == \"square\"\n",
    "            assert example['situation']['placed_objects']['0']['object']['color'] == \"red\" or example['situation']['placed_objects']['1']['object']['color'] == \"red\" or example['situation']['placed_objects']['2']['object']['color'] == \"red\"\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A3: novel size attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset from file: ../../ReaSCAN-v1.0/ReaSCAN-compositional-a3/data-compositional-splits.txt...\n"
     ]
    }
   ],
   "source": [
    "# this test may be a little to weak for now. maybe improve it to verify the shape world?\n",
    "split_test_path_to_data = f\"../../ReaSCAN-v1.0/ReaSCAN-compositional-a3/data-compositional-splits.txt\"\n",
    "print(f\"Reading dataset from file: {split_test_path_to_data}...\")\n",
    "split_test_data = json.load(open(split_test_path_to_data, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in split_test_data[\"examples\"][\"test\"]:\n",
    "    assert \"small,cylinder\" in example['command'] or \\\n",
    "        \"small,red,cylinder\" in example['command'] or \\\n",
    "        \"small,blue,cylinder\" in example['command'] or \\\n",
    "        \"small,yellow,cylinder\" in example['command'] or \\\n",
    "        \"small,green,cylinder\" in example['command']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in ReaSCAN_data[\"examples\"][\"train\"]:\n",
    "    assert not (\"small,cylinder\" in example['command'] or \\\n",
    "        \"small,red,cylinder\" in example['command'] or \\\n",
    "        \"small,blue,cylinder\" in example['command'] or \\\n",
    "        \"small,yellow,cylinder\" in example['command'] or \\\n",
    "        \"small,green,cylinder\" in example['command'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B1: novel co-occurrence of objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset from file: ../../ReaSCAN-v1.0/ReaSCAN-compositional-b1/data-compositional-splits.txt...\n"
     ]
    }
   ],
   "source": [
    "# this test may be a little to weak for now. maybe improve it to verify the shape world?\n",
    "split_test_path_to_data = f\"../../ReaSCAN-v1.0/ReaSCAN-compositional-b1/data-compositional-splits.txt\"\n",
    "print(f\"Reading dataset from file: {split_test_path_to_data}...\")\n",
    "split_test_data = json.load(open(split_test_path_to_data, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, OrderedDict\n",
    "seen_command_structs = {}\n",
    "seen_concepts = {} # add in seen concepts, so we can select concepts that are seen, but new composites!\n",
    "seen_object_co = set([])\n",
    "seen_rel_co = set([])\n",
    "\n",
    "for example_selected in ReaSCAN_data[\"examples\"][\"train\"]:\n",
    "    rel_map = OrderedDict({})\n",
    "    for ele in example_selected[\"relation_map\"]:\n",
    "        rel_map[tuple(ele[0])] = ele[1]\n",
    "    example_struct = OrderedDict({\n",
    "        'obj_pattern_map': example_selected[\"object_pattern_map\"],\n",
    "        'rel_map': rel_map,\n",
    "        'obj_map': example_selected[\"object_expression\"],\n",
    "        'grammer_pattern': example_selected['grammer_pattern'],\n",
    "        'adverb': example_selected['adverb_in_command'],\n",
    "        'verb': example_selected['verb_in_command']\n",
    "    })\n",
    "    obj_co = []\n",
    "    for k, v in example_selected[\"object_expression\"].items():\n",
    "        if v not in seen_concepts:\n",
    "            seen_concepts[v] = 1\n",
    "        else:\n",
    "            seen_concepts[v] += 1\n",
    "        obj_co += [v]\n",
    "    obj_co.sort()\n",
    "    seen_object_co.add(tuple(obj_co))\n",
    "    \n",
    "    rel_co = []\n",
    "    for k, v in rel_map.items():\n",
    "        if v not in seen_concepts:\n",
    "            seen_concepts[v] = 1\n",
    "        else:\n",
    "            seen_concepts[v] += 1\n",
    "        rel_co += [v]\n",
    "    rel_co.sort()\n",
    "    seen_rel_co.add(tuple(rel_co))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seen_command_structs = {}\n",
    "test_seen_concepts = {} # add in seen concepts, so we can select concepts that are seen, but new composites!\n",
    "test_seen_object_co = set([])\n",
    "test_seen_rel_co = set([])\n",
    "\n",
    "for example_selected in split_test_data[\"examples\"][\"test\"]:\n",
    "    rel_map = OrderedDict({})\n",
    "    for ele in example_selected[\"relation_map\"]:\n",
    "        rel_map[tuple(ele[0])] = ele[1]\n",
    "    example_struct = OrderedDict({\n",
    "        'obj_pattern_map': example_selected[\"object_pattern_map\"],\n",
    "        'rel_map': rel_map,\n",
    "        'obj_map': example_selected[\"object_expression\"],\n",
    "        'grammer_pattern': example_selected['grammer_pattern'],\n",
    "        'adverb': example_selected['adverb_in_command'],\n",
    "        'verb': example_selected['verb_in_command']\n",
    "    })\n",
    "    obj_co = []\n",
    "    for k, v in example_selected[\"object_expression\"].items():\n",
    "        if v not in test_seen_concepts:\n",
    "            test_seen_concepts[v] = 1\n",
    "        else:\n",
    "            test_seen_concepts[v] += 1\n",
    "        obj_co += [v]\n",
    "    obj_co.sort()\n",
    "    test_seen_object_co.add(tuple(obj_co))\n",
    "    \n",
    "    rel_co = []\n",
    "    for k, v in rel_map.items():\n",
    "        if v not in test_seen_concepts:\n",
    "            test_seen_concepts[v] = 1\n",
    "        else:\n",
    "            test_seen_concepts[v] += 1\n",
    "        rel_co += [v]\n",
    "    rel_co.sort()\n",
    "    test_seen_rel_co.add(tuple(rel_co))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_seen_object_co.intersection(seen_object_co)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B2: novel co-occurrence of relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset from file: ../../ReaSCAN-v1.0/ReaSCAN-compositional-b2/data-compositional-splits.txt...\n"
     ]
    }
   ],
   "source": [
    "# this test may be a little to weak for now. maybe improve it to verify the shape world?\n",
    "split_test_path_to_data = f\"../../ReaSCAN-v1.0/ReaSCAN-compositional-b2/data-compositional-splits.txt\"\n",
    "print(f\"Reading dataset from file: {split_test_path_to_data}...\")\n",
    "split_test_data = json.load(open(split_test_path_to_data, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seen_command_structs = {}\n",
    "test_seen_concepts = {} # add in seen concepts, so we can select concepts that are seen, but new composites!\n",
    "test_seen_object_co = set([])\n",
    "test_seen_rel_co = set([])\n",
    "\n",
    "for example_selected in split_test_data[\"examples\"][\"test\"]:\n",
    "    rel_map = OrderedDict({})\n",
    "    for ele in example_selected[\"relation_map\"]:\n",
    "        rel_map[tuple(ele[0])] = ele[1]\n",
    "    example_struct = OrderedDict({\n",
    "        'obj_pattern_map': example_selected[\"object_pattern_map\"],\n",
    "        'rel_map': rel_map,\n",
    "        'obj_map': example_selected[\"object_expression\"],\n",
    "        'grammer_pattern': example_selected['grammer_pattern'],\n",
    "        'adverb': example_selected['adverb_in_command'],\n",
    "        'verb': example_selected['verb_in_command']\n",
    "    })\n",
    "    obj_co = []\n",
    "    for k, v in example_selected[\"object_expression\"].items():\n",
    "        if v not in test_seen_concepts:\n",
    "            test_seen_concepts[v] = 1\n",
    "        else:\n",
    "            test_seen_concepts[v] += 1\n",
    "        obj_co += [v]\n",
    "    obj_co.sort()\n",
    "    test_seen_object_co.add(tuple(obj_co))\n",
    "    \n",
    "    rel_co = []\n",
    "    for k, v in rel_map.items():\n",
    "        if v not in test_seen_concepts:\n",
    "            test_seen_concepts[v] = 1\n",
    "        else:\n",
    "            test_seen_concepts[v] += 1\n",
    "        rel_co += [v]\n",
    "    rel_co.sort()\n",
    "    test_seen_rel_co.add(tuple(rel_co))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('$IS_INSIDE', '$SAME_SIZE')}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_seen_rel_co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C1:novel conjunctive clause length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset from file: ../../ReaSCAN-v1.0/ReaSCAN-compositional-c1/data-compositional-splits.txt...\n"
     ]
    }
   ],
   "source": [
    "# this test may be a little to weak for now. maybe improve it to verify the shape world?\n",
    "split_test_path_to_data = f\"../../ReaSCAN-v1.0/ReaSCAN-compositional-c1/data-compositional-splits.txt\"\n",
    "print(f\"Reading dataset from file: {split_test_path_to_data}...\")\n",
    "split_test_data = json.load(open(split_test_path_to_data, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in split_test_data[\"examples\"][\"test\"]:\n",
    "    assert example[\"derivation\"] == \"$OBJ_0 ^ $OBJ_1 & $OBJ_2 & $OBJ_3\"\n",
    "    assert (example[\"command\"].count(\"and\")) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C2:novel relative clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset from file: ../../ReaSCAN-v1.0/ReaSCAN-compositional-c2/data-compositional-splits.txt...\n"
     ]
    }
   ],
   "source": [
    "# this test may be a little to weak for now. maybe improve it to verify the shape world?\n",
    "split_test_path_to_data = f\"../../ReaSCAN-v1.0/ReaSCAN-compositional-c2/data-compositional-splits.txt\"\n",
    "print(f\"Reading dataset from file: {split_test_path_to_data}...\")\n",
    "split_test_data = json.load(open(split_test_path_to_data, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in split_test_data[\"examples\"][\"test\"]:\n",
    "    assert example[\"derivation\"] == \"$OBJ_0 ^ $OBJ_1 ^ $OBJ_2\"\n",
    "    assert (example[\"command\"].count(\"that,is\")) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: No."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
